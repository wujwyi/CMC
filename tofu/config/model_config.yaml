llama2-7b:
  hf_key: "../Llama-2-7b-chat-hf"
  question_start_tag: "[INST] "
  question_end_tag: " [/INST]"
  answer_tag: ""
  flash_attention2: "false"
  gradient_checkpointing: "false"
  ft_model_path: "locuslab/tofu_ft_llama2-7b" #this model will be used for unlearning by default
llama2-13b:
  hf_key: "../Llama-2-13b-chat-hf"
  question_start_tag: "[INST] "
  question_end_tag: " [/INST]"
  answer_tag: ""
  flash_attention2: "false"
  gradient_checkpointing: "false"
Mistral-7B:
  hf_key: "../Mistral-7B-Instruct-v0.1"
  question_start_tag: "[INST] "
  question_end_tag: " [/INST]"
  answer_tag: ""
  flash_attention2: "false"
  gradient_checkpointing: "false"
phi:
  hf_key: "microsoft/phi-1_5"
  question_start_tag: "Question: "
  question_end_tag: "\n"
  answer_tag: "Answer: "
  flash_attention2: "false"
  gradient_checkpointing: "false"
  ft_model_path: "locuslab/tofu_ft_phi-1.5"
stablelm:
  hf_key: "stabilityai/stablelm-3b-4e1t"
  question_start_tag: "Question: "
  question_end_tag: "\n"
  answer_tag: "Answer: "
  flash_attention2: "false"
  gradient_checkpointing: "false"
  ft_model_path: "paper_models/final_ft_noLORA_5_epochs_inst_lr1e-05_stablelm/checkpoint-625"
pythia-1.4:
  hf_key: "EleutherAI/pythia-1.4b-deduped"
  question_start_tag: "Question: "
  question_end_tag: "\n"
  answer_tag: "Answer: "
  flash_attention2: "false"
  gradient_checkpointing: "false"

  
